# Data Preprocessing Exercises

This repository contains a set of hands-on exercises focused on **data preprocessing techniques** using Python and Jupyter Notebooks.  
These exercises demonstrate common tasks in preparing datasets for analysis and machine learning, such as cleaning, transforming, handling missing values, encoding, and scaling.

Data preprocessing is an essential step in any data project — it ensures that your data is in the right form for meaningful analysis and better model performance. 

## Skills Demonstrated

- Loading and inspecting raw data
- Handling missing values and outliers
- Encoding categorical variables
- Feature scaling and normalization
- Transforming and reshaping data
- Documenting preprocessing steps

## Contents

**exercises** - holds notebooks with a self-contained exercise that focuses on a specific preprocessing concept:
- Exercise_1_Pandas_part_1 — Introduction to data preprocessing with pandas, focusing on loading datasets, inspecting data, and basic cleaning operations.  
- Exercise_2_Pandas_part_2 — More advanced pandas preprocessing techniques, including data transformation, aggregation, and handling missing values.  
- Exercise_3_Rest_API — Fetching and preprocessing data from a REST API, including parsing responses and transforming raw JSON data into structured formats.  
- Exercise_4_SQLite — Working with relational data using SQLite, querying databases, and preparing SQL data for further analysis in Python.  
- Exercise_5_Regex — Using regular expressions to clean, extract, and transform unstructured text data.  
- Exercise_6_XML — Parsing and preprocessing XML data, extracting relevant information, and converting it into analyzable formats.  
- Exercise_7_Final — Final preprocessing exercise combining multiple techniques (pandas, APIs, databases, and text processing) into a complete data preparation workflow.

**README.md** - This overview and usage instructions  
**requirements.txt** - Contains libraries used in the notebooks  

## How to Run

1. Clone this repository.
2. Create and activate a virtual environment
    ```
    python3 -m venv venv
    ```
3. Install dependencies:
   ```
    pip install -r requirements.txt
   ```
4. Launch Jupyter Notebook.
5. Open any assignment notebook in the _assignments_ folder and run the cells.  

Together, these exercises demonstrate practical data preprocessing workflows required before analysis or machine learning can be applied.

